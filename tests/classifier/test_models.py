"""
test_models.py

Unit & integration tests for all classification models.
- VGG16 / ResNet152 / MobileNetV2 / MobileNetV3
- Verifies forward pass, parameter freezing, dropout usage, and end-to-end data flow.
"""

import os
import sys
import pytest
import torch
import torch.nn as nn
from PIL import Image

from src.classifier.data.cnn_data_loader import ClassificationDataset
from src.classifier.data.data_preprocessing import DataPreprocessor
from src.classifier.models.factory import get_model


# ==============================================================
# ğŸ§© Helper Functions
# ==============================================================

def run_forward_pass(model_name: str, num_classes: int = 1, input_size=(1, 3, 360, 360)):
    """ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ forward pass ìˆ˜í–‰"""
    model = get_model(model_name, num_classes=num_classes)
    model.eval()
    x = torch.randn(*input_size)
    with torch.no_grad():
        y = model(x)
    return model, y


def compute_loss(output: torch.Tensor):
    """BCEWithLogitsLoss ê³„ì‚° (NaN ë°©ì§€ í™•ì¸ í¬í•¨)"""
    criterion = nn.BCEWithLogitsLoss()
    target = torch.ones_like(output)
    loss = criterion(output, target)
    assert not torch.isnan(loss), "âŒ ì†ì‹¤ ê³„ì‚° ì¤‘ NaN ë°œìƒ"
    return loss.item()


def count_parameters(model: nn.Module):
    """ì „ì²´ ë° í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total, trainable


# ==============================================================
# â‘  Unit Test: Model Structure & Forward
# ==============================================================

@pytest.mark.parametrize(
    "model_name, expect_dropout",
    [
        ("vgg16", True),
        ("resnet152", False),   # ResNetì—ëŠ” Dropout ì—†ìŒ
        ("mobilenet_v2", True),
        ("mobilenet_v3", True),
    ],
)
def test_model_forward_and_structure(model_name, expect_dropout):
    """ëª¨ë¸ forward ë° Dropout ì¡´ì¬ ì—¬ë¶€ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§  [TEST] {model_name.upper()} forward pass & structure ê²€ì¦")

    model, output = run_forward_pass(model_name)

    # âœ… ì¶œë ¥ ì°¨ì› ê²€ì¦
    assert output.ndim == 2 and output.shape[1] == 1, f"{model_name} ì¶œë ¥ shape ì˜¤ë¥˜: {output.shape}"

    # âœ… Dropout ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    has_dropout = any(isinstance(m, nn.Dropout) for m in model.modules())
    assert has_dropout == expect_dropout, (
        f"{model_name}: Dropout ì¡´ì¬ ì—¬ë¶€ ë¶ˆì¼ì¹˜ "
        f"(expected={expect_dropout}, found={has_dropout})"
    )

    # âœ… BCE ì†ì‹¤ ê³„ì‚°
    loss_val = compute_loss(output)
    total_params, trainable_params = count_parameters(model)
    print(f" - BCE Loss: {loss_val:.4f}")
    print(f" - Params: total={total_params:,}, trainable={trainable_params:,}")
    print(f"âœ… {model_name.upper()} êµ¬ì¡° ë° Forward Test í†µê³¼")


# ==============================================================
# â‘¡ Unit Test: Backbone Freeze ë™ì‘ ê²€ì¦
# ==============================================================

@pytest.mark.parametrize("model_name", ["resnet152", "mobilenet_v2", "mobilenet_v3"])
def test_freeze_backbone_option(model_name):
    """freeze_backbone ì˜µì…˜ì´ ì‹¤ì œë¡œ íŒŒë¼ë¯¸í„°ì— ë°˜ì˜ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
    model_frozen = get_model(model_name, freeze_backbone=True)
    model_trainable = get_model(model_name, freeze_backbone=False)

    frozen_params = [p.requires_grad for p in model_frozen.parameters()]
    trainable_params = [p.requires_grad for p in model_trainable.parameters()]

    assert any(trainable_params), f"{model_name}: freeze_backbone=Falseì¸ë° ëª¨ë‘ freezeë¨"
    assert not all(frozen_params), f"{model_name}: freeze_backbone=Trueì¸ë° ì¼ë¶€ trainable"


# ==============================================================
# â‘¢ Integration Test: Data â†’ Transform â†’ Model Pipeline
# ==============================================================

@pytest.mark.parametrize(
    "model_name",
    ["vgg16", "resnet152", "mobilenet_v2", "mobilenet_v3"],
)
def test_real_end_to_end_pipeline(tmp_path, model_name):
    """
    ì‹¤ì œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸:
    1ï¸âƒ£ Dataset â†’ 2ï¸âƒ£ Transform â†’ 3ï¸âƒ£ Model Forward
    """

    print(f"\nğŸ”— [REAL TEST] {model_name.upper()} ì‹¤ì œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")

    # ---------------------------------
    # 1ï¸âƒ£ í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ ë°ì´í„°ì…‹ ìƒì„±
    # ---------------------------------
    data_dir = tmp_path / "data" / "original_crop" / "yolov2" / "train" / "repair"
    data_dir.mkdir(parents=True, exist_ok=True)
    dummy_path = data_dir / "dummy.jpg"

    # (ëœë¤ í”½ì…€ ì´ë¯¸ì§€ ìƒì„±)
    img = Image.fromarray((torch.rand(3, 360, 360).permute(1, 2, 0).numpy() * 255).astype("uint8"))
    img.save(dummy_path)

    # ---------------------------------
    # 2ï¸âƒ£ Dataset + Transform ë¡œë“œ
    # ---------------------------------
    dp = DataPreprocessor(img_size=(360, 360))
    transform = dp.get_transform(model_name=model_name, mode="train")

    dataset = ClassificationDataset(
        input_dir=str(tmp_path / "data" / "original_crop" / "yolov2"),
        split="train",
        transform=transform,  # âœ… ì‹¤ì œ transform ì ìš©
        verbose=True,
    )

    # ---------------------------------
    # 3ï¸âƒ£ ìƒ˜í”Œ ë¡œë“œ ë° ëª¨ë¸ ì…ë ¥ ë³€í™˜
    # ---------------------------------
    img_tensor, label = dataset[0]
    assert isinstance(img_tensor, torch.Tensor), "âŒ Transform í›„ Tensorê°€ ì•„ë‹˜"
    assert img_tensor.shape == (3, 360, 360), f"âŒ ì´ë¯¸ì§€ shape ì˜¤ë¥˜: {img_tensor.shape}"

    x = img_tensor.unsqueeze(0)

    # ---------------------------------
    # 4ï¸âƒ£ ëª¨ë¸ Forward
    # ---------------------------------
    model = get_model(model_name, num_classes=1)
    model.eval()

    with torch.no_grad():
        y = model(x)

    # ---------------------------------
    # 5ï¸âƒ£ ê²°ê³¼ ê²€ì¦
    # ---------------------------------
    assert y.ndim == 2 and y.shape[1] == 1, f"{model_name} ì¶œë ¥ shape ì˜¤ë¥˜: {y.shape}"
    loss_val = compute_loss(y)

    print(f"âœ… {model_name.upper()} ì‹¤ì œ íŒŒì´í”„ë¼ì¸ í†µê³¼ (loss={loss_val:.4f})")