# ðŸ“Š Metrics Directory

This directory contains evaluation results and performance metrics generated after model training and testing.

> âš ï¸ **Note:**  
> All experiments were conducted using **private datasets**.  
> The metric files are provided for documentation and reproducibility of the results described in the paper.  
> Actual values may not be reproducible without access to the private dataset.

---

## ðŸ“ Folder Structure

metrics/
â”œâ”€â”€ annotation_cleaner/
â”‚ â”œâ”€â”€ metrics_full_image.csv
â”‚ â””â”€â”€ metrics_yolo_crop.csv
â”œâ”€â”€ classifier/
â”‚ â”œâ”€â”€ original/
â”‚ â”‚ â”œâ”€â”€ mobilenet_v2_cm.png
â”‚ â”‚ â””â”€â”€ mobilenet_v2_metrics.json
â”‚ â”œâ”€â”€ original_crop/
â”‚ â”‚ â””â”€â”€ yolov8s/
â”‚ â”‚   â”œâ”€â”€ mobilenet_v2_cm.png
â”‚ â”‚   â””â”€â”€ mobilenet_v2_metrics.json
â”‚ â”œâ”€â”€ generation/
â”‚ â”‚ â”œâ”€â”€ mobilenet_v2_cm.png
â”‚ â”‚ â””â”€â”€ mobilenet_v2_metrics.json
â”‚ â””â”€â”€ generation_crop/
â”‚ â”‚ â””â”€â”€ yolov8s/
â”‚ â”‚   â”œâ”€â”€ mobilenet_v2_cm.png
â”‚ â”‚   â””â”€â”€ mobilenet_v2_metrics.json
â””â”€â”€ yolo_cropper/
â”‚ â”‚ â””â”€â”€ yolov2_metrics.csv/
â”‚ â”‚ â””â”€â”€ yolov4, yolov5, yolov8_metrics.csv/


---

## ðŸ§© Description

### 1ï¸âƒ£ Annotation Cleaner Metrics

This subdirectory contains **image similarity evaluation results**  
after removing human-drawn annotations using a generative AI model.

- **Purpose:**  
  To assess how closely the generated clean images match the original ones after annotation removal.

- **Evaluation Types:**  
  - `metrics_full_image.csv` â†’ Measures **global consistency** using full-image comparison.  
  - `metrics_yolo_crop.csv` â†’ Measures **local representation** by comparing only cropped damaged regions.

- **Metrics Columns:**  
split, file, SSIM, Edge_IoU, L1
- **split:** Category of the damage type (e.g., repair / replace).  
- **file:** Image filename.  
- **SSIM:** Structural similarity index (global structure).  
- **Edge_IoU:** Edge overlap between original and generated images (local boundary similarity).  
- **L1:** Pixel-wise intensity difference.

---

### 2ï¸âƒ£ Classifier Metrics

This subdirectory contains **evaluation results for CNN-based classification models**  
trained on original, generated, and cropped datasets.

- **Contents:**
- `*_cm.png` â†’ Confusion matrix visualization.  
- `*_metrics.json` â†’ Quantitative results including accuracy and F1-score.

- **Structure:**
classifier/
â”œâ”€â”€ original/ â†’ Results on original dataset
â”œâ”€â”€ generation/ â†’ Results on generative (bias-removed) dataset
â”œâ”€â”€ original_crop/ â†’ Results on YOLO-cropped original dataset
â””â”€â”€ generation_crop/ â†’ Results on YOLO-cropped generative dataset

- **Typical Metrics:**
```json
{
  "accuracy": 0.945,
  "f1_score": 0.932
}


### 3ï¸âƒ£ YOLO Cropper Metrics

This subdirectory contains the **detection performance results** of YOLO models used for damage-region cropping.

---

#### ðŸ“Œ Purpose
To evaluate and compare the detection accuracy of different YOLO versions  
(`YOLOv2`, `YOLOv4`, `YOLOv5`, `YOLOv8`, etc.) used in the cropping process.

---

#### ðŸ“‚ Files Included
yolo_cropper/
â”œâ”€â”€ yolov2_metrics.csv
â”œâ”€â”€ yolov4_metrics.csv
â”œâ”€â”€ yolov5_metrics.csv
â””â”€â”€ yolov8_metrics.csv

---

#### ðŸ“Š Metrics Columns
Each CSV file includes quantitative detection metrics as follows:
model, precision, recall, mAP@0.5

---

#### ðŸ§¾ Metric Definitions
- **model** â†’ YOLO version or configuration name  
- **precision** â†’ Ratio of correctly detected positive bounding boxes  
- **recall** â†’ Ratio of correctly detected ground-truth regions  
- **mAP@0.5** â†’ Mean Average Precision at IoU threshold 0.5, measuring overall detection performance

---

#### ðŸ“ˆ Example Table

| Model  | Precision | Recall | mAP@0.5 |
|---------|------------|---------|----------|
| YOLOv2  | 0.66       | 0.53    | 34.60 |
| YOLOv4  | 0.74       | 0.70    | 51.09 |
| YOLOv5  | 0.60       | 0.58    | 55.60 |
| YOLOv8  | 0.59       | 0.56    | 56.26 |

---

> ðŸ§  **Note:**  
> These metrics were obtained after evaluating each YOLO model on private datasets.  
> The results demonstrate the relative detection performance of YOLO versions  
> used in the damage-region cropping stage.